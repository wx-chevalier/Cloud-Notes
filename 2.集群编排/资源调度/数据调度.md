# 数据调度

互联网时代的一个重要特点是数据来源广泛，出于数据生产和容灾的需要，数据通常是跨地域摆放在不同地区的不同机房。大数据服务希望容纳所有数据，做到一条 SQL 可以访问到全球任何数据，对这些数据做分析、聚合等操作。但要做到这一点需要面临极大的挑战，其中最大的挑战来自网络。不同于大数据机房内部网络，广域网的网络延迟高、带宽小、价格高、稳定性差，如果每天将全球产生的数据全部集中在一个集群需要极大的网络消耗。考虑到数据量增长的速度远大于广域网发展的速度，很多的大数据计算引擎并没有建一个超大的数据中心将所有数据容纳进来，而是在全球范围根据数据产生的位置就近建设数据中心。

目前工业界成熟的大数据分析系统大都运行在一个数据中心里，跨多数据中心这个方向并没有得到很好地研究。学术界近几年有一些多数据中心调度的工作，但大多致力于 DAG 内 Task 的调度，如 Iridium 期望通过 Task 调度和数据摆放减少跨域网络对任务时效性的影响，Clarinet 提出一种 WAN-aware 的 Query Optimizer，Tetrium 在 Task 和 Job 调度时同时考虑了计算和网络资源因素。这些研究绝大部分更关注单个作业的性能影响，而没有从大数据服务提供商的角度，关注带宽成本和整体性能。

# 数据调度架构

在数据调度中，我们考虑的有优化数据的摆放位置，确定采取什么迁移策略，以及当需要的数据不在本地时，如何进行数据复制和直读、写回，最终实现跨地域长传带宽的流控和整体存储成本的降低。

较为粗放的策略，即考虑数据中心的业务独立。大部分的计算只需要读取内部产生的数据，数据中心之间有少量的数据依赖，由于量比较少，所以作业跨域直接访问数据也不会产生太大流量压力。数据中心各自根据业务需求和增速进行容量规划，包括计算和存储能力的扩容等。初期各数据中心整体负载不高，因此独立规划基本能满足业务的需要。

不过随着业务的不断增长和变化，越来越多的作业需要依赖其他数据中心的数据进行计算，跨域带宽逐渐成为系统瓶颈。另一方面，随着机器规模不断增长，机房、网络等基础设施逐渐成为数据中心进一步扩大规模的障碍，各数据中心独立规划的弊端逐渐暴露，开始出现各数据中心忙闲不均、资源浪费的情况。

为了解决跨域带宽和各数据中心规划中遇到的问题，我们可以在数据中心上层增加了一层调度层，用于调度数据和计算。这层调度独立于数据中心内部的调度，主要目的在于：

- 调度数据，包括数据的迁移和复制。通过迁移数据，均衡各数据中心存储负载，实现集群层面的存储计算分离，并保证不会由于访问远程数据造成带宽雪崩；通过复制（缓存）数据，避免对同一数据的频繁跨域访问，减少带宽消耗；

- 调度计算，包括整体业务的迁移和 SQL 粒度的调度。通过整体业务的迁移，均衡数据中心计算负载，通过将联系紧密的业务放在一起从而减少跨域数据依赖。但业务整体迁移需要迁移大量的历史数据，会消耗大量带宽。因此我们加入了 SQL 粒度的跨机房调度，希望在不迁移或复制数据的情况下，减少带宽消耗（将计算调度到数据所在数据中心）和均衡集群负载。
